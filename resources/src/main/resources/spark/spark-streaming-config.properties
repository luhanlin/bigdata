# spark  流式处理的 配置

#job的并行度
#默认为 1
spark.streaming.concurrentJobs=1

#Spark记忆任何元数据(stages生成，任务生成等等)的时间(秒)。周期性清除保证在这个时间之前的元数据会被遗忘。
#当长时间几小时，几天的运行Spark的时候设置这个是很有用的。注意：任何内存中的RDD只要过了这个时间就会被清除掉。
#默认 disable
spark.cleaner.ttl=3600

#将不再使用的缓存数据清除
#默认为false
spark.streaming.unpersist=true

#\u4ECE\u7F51\u7EDC\u4E2D\u6279\u91CF\u63A5\u53D7\u5BF9\u8C61\u65F6\u7684\u6301\u7EED\u65F6\u95F4 , \u5355\u4F4D  ms\u3002
#\u9ED8\u8BA4\u4E3A200ms 
spark.streaming.blockInterval=200

#控制Receiver速度  单位 s
#因为当streaming程序的数据源的数据量突然变大巨大，可能会导致streaming被撑住导致吞吐不过来，所以可以考虑对于最大吞吐做一下限制。
#默认为 100000
spark.streaming.receiver.maxRate=10000

#kafka每个分区最大的读取速度   单位 s
#控制kafka读取的量
spark.streaming.kafka.maxRatePerPartition=50

#读取kafka的分区最新offset的最大尝试次数
#默认为1
spark.streaming.kafka.maxRetries=5

#1、为什么引入Backpressure
#默认情况下，Spark Streaming通过Receiver以生产者生产数据的速率接收数据，计算过程中会出现batch processing time > batch interval的情况，
#其中batch processing time 为实际计算一个批次花费时间， batch interval为Streaming应用设置的批处理间隔。
#这意味着Spark Streaming的数据接收速率高于Spark从队列中移除数据的速率，也就是数据处理能力低，在设置间隔内不能完全处理当前接收速率接收的数据。
#如果这种情况持续过长的时间，会造成数据在内存中堆积，导致Receiver所在Executor内存溢出等问题（如果设置StorageLevel包含disk, 则内存存放不下的数据会溢写至disk, 加大延迟）。
#Spark 1.5以前版本，用户如果要限制Receiver的数据接收速率，可以通过设置静态配制参数“spark.streaming.receiver.maxRate”的值来实现，
#此举虽然可以通过限制接收速率，来适配当前的处理能力，防止内存溢出，但也会引入其它问题。比如：producer数据生产高于maxRate，当前集群处理能力也高于maxRate，这就会造成资源利用率下降等问题。
#为了更好的协调数据接收速率与资源处理能力，Spark Streaming 从v1.5开始引入反压机制（back-pressure）,通过动态控制数据接收速率来适配集群数据处理能力。
#2、Backpressure
#Spark Streaming Backpressure:  根据JobScheduler反馈作业的执行信息来动态调整Receiver数据接收率。
#通过属性“spark.streaming.backpressure.enabled”来控制是否启用backpressure机制，默认值false，即不启用
spark.streaming.backpressure.enabled=true
spark.streaming.backpressure.initialRate=200